#!/usr/bin/env python3
"""
Comprehensive reporting module for the DER Private Key Analyzer.

This module handles all reporting functionality including:
- Markdown report generation
- Key extraction summaries
- Individual key reports
- Analysis summaries
"""

import os
import base64
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
from models import DERKeyAnalysis


class Reporting:
    """Handles all reporting functionality for the DER Private Key Analyzer."""

    def __init__(self, extracted_keys_dir: Path = None):
        """Initialize the reporting module."""
        self.extracted_keys_dir = extracted_keys_dir or Path("extracted_keys")

    def generate_markdown_report(self, results: List[DERKeyAnalysis], output_file: Optional[str] = None, reference_key: Optional[bytes] = None) -> str:
        """Generate a comprehensive markdown security report."""
        report = []

        # Header
        report.append("# DER Private Key Security Analysis Report")
        report.append("")
        report.append(f"**Analysis Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")

        # Executive Summary
        total_files = len(results)
        files_with_keys = sum(1 for r in results if r.key_found)
        files_with_matching_keys = sum(1 for r in results if r.matches_reference)

        report.append("## Executive Summary")
        report.append("")
        report.append(f"- **Total files analyzed:** {total_files}")
        report.append(f"- **Files with embedded private keys:** {files_with_keys}")
        report.append(f"- **Files with matching reference key:** {files_with_matching_keys}")
        report.append("")

        # Security Risk Assessment
        report.append("## Security Risk Assessment")
        report.append("")
        if files_with_matching_keys > 0:
            report.append("ğŸš¨ **HIGH RISK:** Multiple applications share the same embedded private key")
            report.append("")
            report.append("### Risk Factors")
            report.append("- Private keys can be extracted by reverse engineering")
            report.append("- Compromises security of all affected applications")
            report.append("- Violates secure key management best practices")
            report.append("- Potential for authentication bypass attacks")
        else:
            report.append("âœ… **LOW RISK:** No shared embedded private keys detected")
        report.append("")

        # Detailed Results
        report.append("## Detailed Analysis Results")
        report.append("")

        for i, result in enumerate(results, 1):
            report.append(f"### {i}. {os.path.basename(result.file_path)}")
            report.append("")
            report.append(f"- **File size:** {result.file_size:,} bytes")
            report.append(f"- **Key found:** {'YES' if result.key_found else 'NO'}")

            if result.key_found:
                report.append(f"- **Key offset:** `0x{result.key_offset:x}`")
                report.append(f"- **Key length:** {result.key_length} bytes")
                report.append(f"- **Key hash:** `{result.key_hash[:16]}...`")
                report.append(f"- **Public key:** `{result.public_key[:32]}...`")
            report.append("")

        report.append("")

        # Technical Details
        report.append("## Technical Details")
        report.append("")
        report.append("### Key Properties")
        if any(r.key_found for r in results):
            report.append("- **Format:** DER-encoded ECDSA private key")
            report.append("- **Algorithm:** ECDSA with P-256 curve")
            report.append("- **Security:** 256-bit key strength")
        report.append("")
        report.append("### Detection Method")
        report.append("- Binary pattern matching for DER structures")
        report.append("- ASN.1 structure analysis")
        report.append("- Cryptographic algorithm identification")
        report.append("")

        # Footer
        report.append("---")
        report.append("*Report generated by DER Private Key Analyzer*")

        report_text = "\n".join(report)

        if output_file:
            with open(output_file, 'w') as f:
                f.write(report_text)
            print(f"Markdown report saved to: {output_file}")

        return report_text

    def generate_key_summary_report(self, all_results: Dict[str, List[DERKeyAnalysis]], output_dir: str = "extracted_keys") -> str:
        """Generate a summary report of all distinct keys found across all files."""
        import os
        from pathlib import Path

        # Create summary subfolder
        summary_dir = Path(output_dir) / "key_summary"
        summary_dir.mkdir(exist_ok=True)

        # Collect all keys and group by hash
        key_groups = {}
        for file_path, keys in all_results.items():
            for key in keys:
                if key.key_found:
                    if key.key_hash not in key_groups:
                        key_groups[key.key_hash] = []
                    key_groups[key.key_hash].append(key)

        # Generate summary report for each distinct key
        summary_files = []
        for key_hash, keys in key_groups.items():
            if len(keys) > 0:
                # Create filename using key hash
                filename = f"{key_hash[:16]}.md"
                file_path = summary_dir / filename

                # Generate markdown content
                content = self._generate_key_summary_markdown(key_hash, keys)

                # Write file
                with open(file_path, 'w') as f:
                    f.write(content)

                summary_files.append(str(file_path))
                print(f"  âœ“ Generated key summary: {filename}")

        # Generate master summary
        master_summary = self._generate_master_summary(key_groups)
        master_file = summary_dir / "00_MASTER_SUMMARY.md"
        with open(master_file, 'w') as f:
            f.write(master_summary)

        print(f"  âœ“ Generated master summary: 00_MASTER_SUMMARY.md")
        summary_files.append(str(master_file))

        return str(summary_dir)

    def _generate_key_summary_markdown(self, key_hash: str, keys: List[DERKeyAnalysis]) -> str:
        """Generate markdown for a specific key showing all files that contain it."""
        content = []

        content.append(f"# Private Key Summary")
        content.append("")
        content.append(f"**Key Hash:** `{key_hash}`")
        content.append(f"**Total Files:** {len(keys)}")
        content.append(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        content.append("")

        # Key information
        if keys:
            first_key = keys[0]
            content.append("## ğŸ”‘ Key Information")
            content.append("")
            content.append(f"- **Algorithm:** ECDSA P-256")
            content.append(f"- **Format:** DER-encoded")
            content.append(f"- **Security Level:** 256-bit")
            content.append(f"- **Length:** {first_key.key_length} bytes")
            content.append("")

            # Add PEM content
            content.append("## ğŸ” Private Key (PEM Format)")
            content.append("")
            content.append("```pem")
            try:
                # Extract key data from the first file containing this key
                with open(first_key.file_path, 'rb') as f:
                    f.seek(first_key.key_offset)
                    key_data = f.read(first_key.key_length)
                    pem_content = self._generate_pem_format(key_data)
                    content.append(pem_content)
            except Exception as e:
                content.append(f"Error extracting key data: {e}")
            content.append("```")
            content.append("")

            # Add detailed key information
            content.append("## ğŸ”“ Public Key Information")
            content.append("")
            content.append(f"- **Public Key Hash:** `{first_key.public_key}`")
            content.append(f"- **Key Type:** {first_key.key_type or 'ECDSA P-256 Public Key'}")
            content.append(f"- **Extracted From:** Private key DER structure")
            content.append("")

            # Add comprehensive key details
            content.append("## ğŸ” Detailed Key Analysis")
            content.append("")
            content.append(f"- **Algorithm:** {first_key.algorithm_name or 'ECDSA'}")
            content.append(f"- **Curve:** {first_key.curve_name or 'P-256'}")
            content.append(f"- **Key Size:** {first_key.key_size or '256 bits'}")
            content.append(f"- **Security Level:** {first_key.security_level or 'High'}")
            content.append(f"- **Usage:** {first_key.usage or 'Digital Signature and Authentication'}")
            content.append(f"- **Key ID:** {first_key.key_id or 'Unknown'}")
            content.append("")

            # Add raw key data
            if first_key.private_key_hex:
                content.append("## ğŸ” Raw Key Data")
                content.append("")
                content.append("### Private Key (Hex)")
                content.append("```")
                content.append(first_key.private_key_hex)
                content.append("```")
                content.append("")
                content.append("### Public Key (Hex)")
                content.append("```")
                content.append(first_key.public_key)
                content.append("```")
                content.append("")

        # Files containing this key
        content.append("## ğŸ“ Files Containing This Key")
        content.append("")
        content.append("| File | Offset | Length | Section |")
        content.append("|------|--------|--------|---------|")

        for key in keys:
            # Include parent folder name to distinguish files with same name
            file_name = os.path.basename(key.file_path)
            parent_folder = os.path.basename(os.path.dirname(key.file_path))
            display_name = f"{parent_folder}/{file_name}" if parent_folder else file_name
            offset_hex = f"0x{key.key_offset:x}"
            section = key.section_name or "Unknown"
            content.append(f"| `{display_name}` | `{offset_hex}` | {key.key_length} bytes | {section} |")

        content.append("")

        # Detailed file information
        content.append("## ğŸ“‹ Detailed File Information")
        content.append("")
        for i, key in enumerate(keys, 1):
            file_name = os.path.basename(key.file_path)
            parent_folder = os.path.basename(os.path.dirname(key.file_path))
            display_name = f"{parent_folder}/{file_name}" if parent_folder else file_name
            content.append(f"### {i}. {display_name}")
            content.append("")
            content.append(f"- **Full Path:** `{key.file_path}`")
            content.append(f"- **File Size:** {key.file_size:,} bytes")
            content.append(f"- **Key Offset:** `0x{key.key_offset:x}`")
            content.append(f"- **Key Length:** {key.key_length} bytes")
            if key.section_name:
                content.append(f"- **PE Section:** {key.section_name}")
            if key.resource_type:
                content.append(f"- **Resource Type:** {key.resource_type}")
            if key.resource_name:
                content.append(f"- **Resource Name:** {key.resource_name}")
            if key.location_description:
                content.append(f"- **Location:** {key.location_description}")
            content.append("")

        return "\n".join(content)

    def _generate_master_summary(self, key_groups: Dict[str, List[DERKeyAnalysis]]) -> str:
        """Generate master summary of all keys found."""
        content = []

        content.append("# Master Key Summary Report")
        content.append("")
        content.append(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        content.append(f"**Total Distinct Keys:** {len(key_groups)}")
        content.append("")

        # Count total files and keys
        total_files = set()
        total_keys = 0
        for keys in key_groups.values():
            total_keys += len(keys)
            for key in keys:
                total_files.add(key.file_path)

        content.append(f"**Total Files Analyzed:** {len(total_files)}")
        content.append(f"**Total Key Instances:** {total_keys}")
        content.append("")

        # Security overview
        content.append("## ğŸš¨ Security Overview")
        content.append("")
        shared_keys = [k for k, v in key_groups.items() if len(v) > 1]
        unique_keys = [k for k, v in key_groups.items() if len(v) == 1]

        content.append(f"- **Shared Keys:** {len(shared_keys)} (keys found in multiple files)")
        content.append(f"- **Unique Keys:** {len(unique_keys)} (keys found in single files)")
        content.append("")

        if shared_keys:
            content.append("**Shared Keys Found:**")
            content.append("")
            content.append("The following keys are embedded in multiple executable files:")
            content.append("")
            for key_hash in shared_keys:
                keys = key_groups[key_hash]
                file_names = []
                for k in keys:
                    file_name = os.path.basename(k.file_path)
                    parent_folder = os.path.basename(os.path.dirname(k.file_path))
                    display_name = f"{parent_folder}/{file_name}" if parent_folder else file_name
                    file_names.append(display_name)
                content.append(f"- **Key `{key_hash}`**: Found in {len(keys)} files")
                content.append(f"  - Files: {', '.join(file_names)}")
            content.append("")

        # Summary table
        content.append("## ğŸ“Š Key Summary Table")
        content.append("")
        content.append("| Key Hash | Files | Instances | Status |")
        content.append("|----------|-------|-----------|--------|")

        for key_hash, keys in sorted(key_groups.items(), key=lambda x: len(x[1]), reverse=True):
            file_count = len(set(k.file_path for k in keys))
            instance_count = len(keys)
            status = "ğŸš¨ SHARED" if len(keys) > 1 else "âœ… UNIQUE"
            content.append(f"| `{key_hash[:16]}...` | {file_count} | {instance_count} | {status} |")

        content.append("")

        # Individual key reports
        content.append("## ğŸ“ Individual Key Reports")
        content.append("")
        content.append("Detailed reports for each key are available in the following files:")
        content.append("")

        for key_hash in sorted(key_groups.keys()):
            filename = f"{key_hash[:16]}.md"
            keys = key_groups[key_hash]
            file_count = len(set(k.file_path for k in keys))
            content.append(f"- **[{filename}]({filename})** - {file_count} files, {len(keys)} instances")

        return "\n".join(content)

    def generate_key_markdown(self, der_data: bytes, file_path: str, key_hash: str, analysis_result: DERKeyAnalysis = None) -> str:
        """Generate markdown format for an individual private key."""
        content = []

        content.append(f"# Extracted Private Key")
        content.append("")
        content.append(f"**Source:** `{file_path}`")
        content.append(f"**Hash:** `{key_hash}`")
        content.append(f"**Length:** {len(der_data)} bytes")
        content.append(f"**Extracted:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # Add offset information if available
        if analysis_result and analysis_result.key_offset is not None:
            content.append(f"**File Offset:** `0x{analysis_result.key_offset:x}`")

        # Add location information if available
        if analysis_result and analysis_result.location_description:
            content.append(f"**Location:** {analysis_result.location_description}")
            if analysis_result.section_name:
                content.append(f"**Section:** {analysis_result.section_name}")
            if analysis_result.resource_type:
                content.append(f"**Resource Type:** {analysis_result.resource_type}")
            if analysis_result.resource_name:
                content.append(f"**Resource Name:** {analysis_result.resource_name}")

        content.append("")
        content.append("## ğŸ”‘ Private Key (PEM Format)")
        content.append("")
        content.append("```pem")
        content.append(self._generate_pem_format(der_data))
        content.append("```")
        content.append("")
        content.append("## ğŸ“Š Key Information")
        content.append("")
        content.append(f"- **Algorithm:** ECDSA P-256")
        content.append(f"- **Format:** DER-encoded")
        content.append(f"- **Security Level:** 256-bit")

        # Add location details if available
        if analysis_result and analysis_result.location_description:
            content.append("")
            content.append("## ğŸ“ Location Details")
            content.append("")
            content.append(f"- **Location:** {analysis_result.location_description}")
            if analysis_result.section_name:
                content.append(f"- **PE Section:** {analysis_result.section_name}")
            if analysis_result.resource_type:
                content.append(f"- **Resource Type:** {analysis_result.resource_type}")
            if analysis_result.resource_name:
                content.append(f"- **Resource Name:** {analysis_result.resource_name}")
            if analysis_result.key_offset is not None:
                content.append(f"- **File Offset:** 0x{analysis_result.key_offset:x}")

        return "\n".join(content)

    def _generate_pem_format(self, der_data: bytes) -> str:
        """Generate PEM format from DER data."""
        try:
            b64_data = base64.b64encode(der_data).decode('ascii')
            pem_content = f"-----BEGIN PRIVATE KEY-----\n"

            # Split into 64-character lines
            for i in range(0, len(b64_data), 64):
                pem_content += b64_data[i:i+64] + "\n"

            pem_content += "-----END PRIVATE KEY-----\n"
            return pem_content
        except:
            return ""

    def list_extracted_keys(self) -> List[Dict[str, str]]:
        """List all extracted keys with their metadata."""
        extracted_keys = []

        if not self.extracted_keys_dir.exists():
            return extracted_keys

        # Find all markdown files and extract metadata from filenames
        for md_file in self.extracted_keys_dir.glob("*.md"):
            try:
                # Extract metadata from filename: parent_dir_filename_hash.md
                filename = md_file.stem
                if '_' in filename:
                    # Split into parts: parent_dir_filename and hash
                    parts = filename.split('_')
                    if len(parts) >= 2:
                        # Last part is the hash
                        hash_part = parts[-1]
                        # Everything before the last part is the source
                        source_part = '_'.join(parts[:-1])

                        key_info = {
                            'source_file': source_part,
                            'key_hash': hash_part,
                            'key_length': 138,  # Standard ECDSA P-256 length
                            'algorithm': 'ECDSA',
                            'curve': 'P-256',
                            'extracted_files': {'md': str(md_file)}
                        }
                        extracted_keys.append(key_info)
            except Exception as e:
                print(f"Error reading metadata from {md_file}: {e}")

        return extracted_keys

    def generate_extraction_summary(self) -> str:
        """Generate a summary of extracted keys."""
        extracted_keys = self.list_extracted_keys()

        if not extracted_keys:
            return "No keys have been extracted yet."

        summary = []
        summary.append("ğŸ“ EXTRACTED KEYS SUMMARY")
        summary.append("=" * 50)
        summary.append("")

        for i, key_info in enumerate(extracted_keys, 1):
            summary.append(f"{i}. {key_info.get('source_file', 'Unknown')}")
            summary.append(f"   Hash: {key_info.get('key_hash', 'Unknown')[:16]}...")
            summary.append(f"   Length: {key_info.get('key_length', 0)} bytes")
            summary.append(f"   Algorithm: {key_info.get('algorithm', 'Unknown')}")
            summary.append(f"   Curve: {key_info.get('curve', 'Unknown')}")

            extracted_files = key_info.get('extracted_files', {})
            if extracted_files:
                md_file = extracted_files.get('md', '')
                if md_file:
                    summary.append(f"   File: {os.path.basename(md_file)}")
            summary.append("")

        summary.append(f"Total extracted keys: {len(extracted_keys)}")
        summary.append(f"Extraction directory: {self.extracted_keys_dir}")
        summary.append("")
        summary.append("ğŸ’¡ TIP: Read the .md files for key information")

        return "\n".join(summary)

    def generate_analysis_summary(self, results: List[DERKeyAnalysis]) -> str:
        """Generate a concise analysis summary."""
        total_files = len(results)
        files_with_keys = sum(1 for r in results if r.key_found)
        files_with_matching_keys = sum(1 for r in results if r.matches_reference)

        summary = []
        summary.append("Analysis complete:")
        summary.append(f"  Files analyzed: {total_files}")
        summary.append(f"  Files with keys: {files_with_keys}")
        summary.append(f"  Files with matching keys: {files_with_matching_keys}")

        if files_with_matching_keys > 0:
            summary.append("  ğŸ“Š Shared embedded private keys detected")
        else:
            summary.append("  âœ… No shared embedded private keys found")

        return "\n".join(summary)
